{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%pip install --quiet -U langchain\\n%pip install --quiet -U  langchain_community\\n%pip install --quiet -U  tiktoken\\n%pip install --quiet -U langchain-nomic \"nomic[local]\"\\n%pip install --quiet -U langchain-ollama\\n%pip install --quiet -U  scikit-learn\\n%pip install --quiet -U langgraph\\n%pip install --quiet -U tavily-python bs4\\n%pip install PyMuPDF\\n%pip install Spacy\\n# %pip install sentence-transformers #to use \\'all-mpnet-base-v5\\' embedding model\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dependencies\n",
    "\"\"\"\n",
    "%pip install --quiet -U langchain\n",
    "%pip install --quiet -U  langchain_community\n",
    "%pip install --quiet -U  tiktoken\n",
    "%pip install --quiet -U langchain-nomic \"nomic[local]\"\n",
    "%pip install --quiet -U langchain-ollama\n",
    "%pip install --quiet -U  scikit-learn\n",
    "%pip install --quiet -U langgraph\n",
    "%pip install --quiet -U tavily-python bs4\n",
    "%pip install PyMuPDF\n",
    "%pip install Spacy\n",
    "# %pip install sentence-transformers #to use 'all-mpnet-base-v5' embedding model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\Documents\\Falah Naveed\\SpexRAG\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "# from sentence_transformers import SentenceTransformer # to use 'all-mpnet-base-v5' embedding model\n",
    "from tqdm.auto import tqdm\n",
    "from spacy.lang.en import English # see https://spacy.io/usage for install instructions\n",
    "import fitz #(pymupdf, found this is better than pypdf for our use case, note: licence is AGPL-3.0, keep that in mind if you want to use any code commercially)\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 17 01:00:28 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   32C    P8              8W /  285W |       0MiB /  16376MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining functions\n",
    "\n",
    "# Get PDF documents\n",
    "def get_file_paths(folder_path):\n",
    "    file_paths = []  # Initialize an empty list\n",
    "\n",
    "    # Check if the provided folder path exists and is a directory\n",
    "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "        # Iterate through the files in the folder\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                # Construct the full file path and append it to the list\n",
    "                if file.endswith(\".pdf\"):  # Ensure only PDF files are considered\n",
    "                    file_paths.append(os.path.join(root, file))\n",
    "    else:\n",
    "        print(f\"The provided path '{folder_path}' is not a valid directory.\")\n",
    "\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "#Performs minor formatting on text.\n",
    "def text_formatter(text: str) -> str:\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip() # note: this might be different for each doc (best to experiment)\n",
    "    # Other potential text formatting functions can go here\n",
    "    return cleaned_text\n",
    "\n",
    "# Open PDF and get lines/pages\n",
    "# Note: this only focuses on text, rather than images/figures etc\n",
    "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
    "    doc = fitz.open(pdf_path)  # open a document\n",
    "    pages_and_texts = []\n",
    "    for page_number, page in tqdm(enumerate(doc), desc=f\"Reading {pdf_path}\"):  # iterate document pages\n",
    "        text = page.get_text()  # get plain text encoded as UTF-8\n",
    "        text = text_formatter(text)\n",
    "        pages_and_texts.append({\n",
    "            \"file_name\": os.path.basename(pdf_path),\n",
    "            \"page_number\": page_number,  # PDF page numbers start at 0\n",
    "            \"page_char_count\": len(text),\n",
    "            \"page_word_count\": len(text.split()),\n",
    "            \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "            \"page_token_count\": len(text) / 4,  # 1 token = ~4 chars\n",
    "            \"text\": text\n",
    "        })\n",
    "    return pages_and_texts\n",
    "\n",
    "# Recursively splits a list into desired sizes\n",
    "def split_list(input_list: list, \n",
    "               slice_size: int) -> list[list[str]]:\n",
    "    \"\"\"\n",
    "    Splits the input_list into sublists of size slice_size (or as close as possible).\n",
    "\n",
    "    For example, a list of 17 sentences would be split into two lists of [[10], [7]]\n",
    "    \"\"\"\n",
    "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "#\n",
    "\n",
    "def map_dict_to_document(data: dict[str, any]) -> Document:\n",
    "    \"\"\"\n",
    "    Map a dictionary to a Langchain Document object.\n",
    "\n",
    "    Args:\n",
    "        data (Dict[str, Any]): The dictionary containing keys like 'page_content', \n",
    "                               'page_number', etc.\n",
    "\n",
    "    Returns:\n",
    "        Document: A Document object with the mapped data.\n",
    "    \"\"\"\n",
    "    page_content = data.get('page_content', '')\n",
    "    metadata = {key: value for key, value in data.items() if key != 'page_content'}\n",
    "    return Document(page_content=page_content, metadata=metadata)\n",
    "\n",
    "# Post-processing of retrieved chunks to join them before passing to LLMs\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Context\\CMX608-data-sheet.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Context\\CMX608-data-sheet.pdf: 70it [00:00, 178.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Context\\DS_SX1276-7-8-9_W_APP_V7 (1).pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Context\\DS_SX1276-7-8-9_W_APP_V7 (1).pdf: 132it [00:00, 507.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Context\\MAX-M10S_DataSheet_UBX-20035208.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Context\\MAX-M10S_DataSheet_UBX-20035208.pdf: 24it [00:00, 421.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Context\\nRF24L01Pluss_Preliminary_Product_Specification_v1_0.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Context\\nRF24L01Pluss_Preliminary_Product_Specification_v1_0.pdf: 75it [00:00, 604.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Context\\SARA-R4_DataSheet_UBX-16024152.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Context\\SARA-R4_DataSheet_UBX-16024152.pdf: 51it [00:00, 150.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Context\\Si4468-7.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Context\\Si4468-7.pdf: 57it [00:00, 647.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Context\\sx1276-1278113.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Context\\sx1276-1278113.pdf: 133it [00:00, 490.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 7 PDF files.\n",
      "Total pages collected: 542\n",
      "Sentencizing texts on all pages in all pdfs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 542/542 [00:01<00:00, 444.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making chunks of ~10 sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 542/542 [00:00<00:00, 542168.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split each chunk into its own item\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 542/542 [00:00<00:00, 22582.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting chunks into langchain compatible format. i.e. 'document objects'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 997/997 [00:00<00:00, 332410.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Embeddings in the Vector Store using 'nomic-embed-text-v1.5'\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"Context\" #path to folder containing PDFs, for now its a folder called 'Context'\n",
    "local_llm = \"llama3.2:3b-instruct-fp16\" #define which model to use from ollama, make sure to ollama pull model before using here\n",
    "num_sentence_chunk_size = 10 # Define split size to turn groups of sentences into chunks\n",
    "\n",
    "llm = ChatOllama(model=local_llm, temperature=0.5) #instantiating model to call in our script\n",
    "\n",
    "# Embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", device=\"cpu\") # choose the device to load the model to (note: GPU will often be much* faster than CPU)\n",
    "embedding_model= NomicEmbeddings(model=\"nomic-embed-text-v1.5\", inference_mode=\"local\", device=\"nvidia\")\n",
    "\n",
    "#SpaCy sentencizer for preprocessing\n",
    "nlp = English() # Add a sentencizer pipeline, see https://spacy.io/api/sentencizer/ \n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# Make a list of files in a given folder\n",
    "file_list = get_file_paths(folder_path)\n",
    "\n",
    "# Now reading files\n",
    "all_pages_and_texts = []  # This will hold the combined results\n",
    "for pdf_path in file_list:\n",
    "    print(f\"Reading {pdf_path}\")\n",
    "    file_pages_and_texts = open_and_read_pdf(pdf_path)\n",
    "    all_pages_and_texts.extend(file_pages_and_texts)  # Append all pages from the current file\n",
    "\n",
    "# Print summary\n",
    "print(f\"Processed {len(file_list)} PDF files.\")\n",
    "print(f\"Total pages collected: {len(all_pages_and_texts)}\")\n",
    "\n",
    "print(\"Sentencizing texts on all pages in all pdfs\")\n",
    "for item in tqdm(all_pages_and_texts):\n",
    "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
    "\n",
    "    # Make sure all sentences are strings\n",
    "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "    \n",
    "    # Count the sentences \n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])\n",
    "\n",
    "print(f\"Making chunks of ~{num_sentence_chunk_size} sentences\")\n",
    "# Loop through pages and texts and split sentences into chunks\n",
    "for item in tqdm(all_pages_and_texts):\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
    "                                         slice_size=num_sentence_chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])\n",
    "\n",
    "print(f\"Split each chunk into its own item\")\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(all_pages_and_texts):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "        \n",
    "        # Join the sentences together into a paragraph-like structure, aka a chunk (so they are a single string)\n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # \".A\" -> \". A\" for any full-stop/capital letter combo \n",
    "        chunk_dict[\"page_content\"] = joined_sentence_chunk\n",
    "\n",
    "        # Get stats about the chunk\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4 # 1 token = ~4 characters\n",
    "        \n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "chunks=[]\n",
    "print(f\"Converting chunks into langchain compatible format. i.e. 'document objects'\")\n",
    "for page_and_chunk in tqdm(pages_and_chunks):\n",
    "    document = map_dict_to_document(page_and_chunk)  # Use the map_dict_to_document function\n",
    "    chunks.append(document)\n",
    "\n",
    "print(f\"Creating Embeddings in the Vector Store using '{embedding_model.model}'\")\n",
    "vectorstore = SKLearnVectorStore.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model\n",
    ")\n",
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 7})\n",
    "\n",
    "# deifining default propmpts\n",
    "Spex = SystemMessage(\n",
    "        content=\"You are SpexRAG - an embedded systems engineer's AI assistant, Your job is to look at datasheets and helps other embedded systems engineers in their workflow, you think carefully befor answering and you are keen on every single detail\"\n",
    "    )\n",
    "Intro = HumanMessage(content=\"Hi, Introduce yourself. How can you help us today\")\n",
    "rag_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "\n",
    "Here is the context to use to answer the question:\n",
    "\n",
    "{context} \n",
    "\n",
    "Think carefully about the above context. \n",
    "\n",
    "Now, review the user question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Provide an answer to this questions using the above context. keep the answer concise.\n",
    "\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 7 documents\n",
      "User:  tell me about vctrl in cmx638\n",
      "SpexRAG:  The VCTRL register ($07) is used to configure the CMX638's DTMF mode. Setting bit 7 of VCFG to '1' enables Format 2, which corresponds to a standard telephone keypad matrix layout (DTMF - Format 2). This allows the device to send or receive single tones and reproduce naturally occurring tones at the other end of a Vocoded link.\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "question=input()\n",
    "docs = retriever.invoke(question)\n",
    "print(f\"Retrieved {len(docs)} documents\")\n",
    "docs_txt = format_docs(docs)\n",
    "rag_prompt_formatted = rag_prompt.format(context=docs_txt, question=question)\n",
    "generation = llm.invoke([Spex, HumanMessage(content=rag_prompt_formatted)])\n",
    "print(\"User:  \" + question)\n",
    "print(\"SpexRAG:  \" + generation.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
